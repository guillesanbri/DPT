project: "Benchmarking"
name: "Inference-speed-Sweep"
program: inference_speed.py
method: grid
parameters:
  mixed_precision:
    values:
    - True
    - False
  input_size:
    values:
    - "192,640"
    - "352,1216"
  backbone:
    values:
    - "vitb_effb0"
    - "vitb_rn50_384"
  transformer_hooks:
    values:
    - "str:0,1"
    - "str:2,5"
    - "str:8,11"
  attention_variant:
    values:
    - "performer"
    - "None"
  attention_heads:
    values:
    - 1
    - 12
    - 24